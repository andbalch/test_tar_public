{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('test_tar_json_parse': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8a460167d8aa885cb47d5964c71ac3986484241d23a3d8e5e10c68c298a08e19"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Exploration JSON Parser\n",
    "The goal of this notebook is to flatten and extract the data into .csv from .apk.json files included un the MalDroid dataset containing the CopperDroid analysis of android APKs. This notebook focuses on the data included under the dynamic:host: headers of the JSON file. This is done to be able to more easily visualize and analyze the houndreds of thousands of rows of sys calls. \n",
    "## Objectives\n",
    "1. Isolate the data under the 'dynamic' header into a JSON array under the header 'host'\n",
    "2. Create seperate JSON files of objects with the same \"class\" attribute\n",
    "3. Record a nested dictionary of common attributes associated with each \"class\" attribute\n",
    "4. Flatten \"class\"-separated JSON files into their own CSVs for analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "with open('075049984D2937039DDE452818BC6B844C8C8CD17232DB8D951306F02234B2EA/sample_for_analysis.apk.json') as path:\n",
    "    full_json = json.load(path)"
   ]
  },
  {
   "source": [
    "# Objective 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "isolated_json = full_json['behaviors']['dynamic']"
   ]
  },
  {
   "source": [
    "# Objective 2\n",
    "A list of all class names is compilied and the dictionary is formed. Then the dictionary entries are exported to JSON and a dictionary is formed and exported of the relative file paths for each class for refrence."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_list = []\n",
    "class_dict = {}\n",
    "\n",
    "for item in isolated_json['host']:\n",
    "    if type(item) != dict:\n",
    "        print(\"item not of type dict\")\n",
    "        break\n",
    "    item_class = item['class']\n",
    "    if item_class not in class_list:\n",
    "        class_list.append(item_class)\n",
    "        class_dict[item_class] = [item]\n",
    "    else:\n",
    "        class_dict[item_class].append(item)\n",
    "        \n",
    "file_path_dict = {}\n",
    "\n",
    "for class_type in class_dict.keys():\n",
    "    holder_dict = {'content': class_dict[class_type]}\n",
    "    path = 'data_exploration/' + class_type + '.json'\n",
    "    file_path_dict[class_type] = path\n",
    "    with open('data_exploration/' + class_type + '.json', 'w') as write_json:\n",
    "        json.dump(holder_dict, write_json)\n",
    "\n",
    "with open('data_exploration/relative_class_file_paths.json', 'w') as write_json:\n",
    "        json.dump(file_path_dict, write_json)"
   ]
  },
  {
   "source": [
    "# Objective 3\n",
    "Variances in the structure of objects even within the same class need to be noted and accounted for. Each dictionary contains a list of the possible structures within a class. Attributes are treated as keys in the dictionary, where the values are their corresponding dtypes or sub-Attributes with their own dictionaries.\n",
    "The end result is a JSON object where the primary Attributes are each class type, containing a list of dictionaries of each possible structure within that class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class_attributes_dict = {}\n",
    "\n",
    "def dictparse(item):\n",
    "    #A bit messy, but seems to be accurate. Had to workaround some strange formatting, long dtypes, and unicode\n",
    "    attribute_dict = {}\n",
    "    for key in item.keys():\n",
    "        attribute = item[key]\n",
    "        if key == 'blob' and type(attribute) is str:\n",
    "            if '{' in attribute:\n",
    "                attribute = attribute.replace(\"L,\", \",\")\n",
    "                attribute = attribute.replace(\"L}\", \"}\")\n",
    "                attribute = attribute.replace(\"u\\'\", \"\\'\")\n",
    "                try:\n",
    "                    attribute = ast.literal_eval(attribute)\n",
    "                except:\n",
    "                    print(item)\n",
    "        if type(attribute) is dict:\n",
    "            attribute_dict[key] = dictparse(attribute)\n",
    "        elif type(attribute) is list:\n",
    "            #WARNING: This does not account for n-dimensional lists\n",
    "            for entry in attribute:\n",
    "                if type(entry) is dict:\n",
    "                    attribute_dict[key] = dictparse(entry)\n",
    "                else:\n",
    "                    attribute_dict[key] = str(type(attribute))\n",
    "        else:\n",
    "            attribute_dict[key] = str(type(attribute))\n",
    "    return attribute_dict\n",
    "\n",
    "for class_type in class_dict.keys():\n",
    "    class_attributes_dict[class_type] = []\n",
    "    for item in class_dict[class_type]:\n",
    "        item_dict = dictparse(item)\n",
    "        if item_dict not in class_attributes_dict[class_type]:\n",
    "            class_attributes_dict[class_type].append(item_dict)\n",
    "\n",
    "with open('data_exploration/class_attributes.json', 'w') as write_json:\n",
    "        json.dump(class_attributes_dict, write_json)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "source": [
    "# Objective 4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}