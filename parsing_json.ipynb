{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('test_tar_json_parse': conda)",
   "metadata": {
    "interpreter": {
     "hash": "8a460167d8aa885cb47d5964c71ac3986484241d23a3d8e5e10c68c298a08e19"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Exploration JSON Parser\n",
    "The goal of this notebook is to flatten and extract the data into .csv from .apk.json files included un the MalDroid dataset containing the CopperDroid analysis of android APKs. This notebook focuses on the data included under the dynamic:host: headers of the JSON file. This is done to be able to more easily visualize and analyze the houndreds of thousands of rows of sys calls. \n",
    "## Objectives\n",
    "1. Isolate the data under the 'dynamic' header into a JSON array under the header 'host'\n",
    "2. Create seperate JSON files of objects with the same \"class\" attribute\n",
    "3. Record a nested dictionary of common attributes associated with each \"class\" attribute\n",
    "4. Flatten \"class\"-separated JSON files into their own CSVs for analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "from flatten_json import flatten\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "with open('075049984D2937039DDE452818BC6B844C8C8CD17232DB8D951306F02234B2EA/sample_for_analysis.apk.json') as path:\n",
    "    full_json = json.load(path)"
   ]
  },
  {
   "source": [
    "# Objective 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "isolated_json = full_json['behaviors']['dynamic']"
   ]
  },
  {
   "source": [
    "# Objective 2\n",
    "A list of all class names is compilied and the dictionary is formed. Then the dictionary entries are exported to JSON and a dictionary is formed and exported of the relative file paths for each class for refrence."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_list = []\n",
    "class_dict = {}\n",
    "\n",
    "for item in isolated_json['host']:\n",
    "    if type(item) != dict:\n",
    "        print(\"item not of type dict\")\n",
    "        break\n",
    "    item_class = item['class']\n",
    "    if item_class not in class_list:\n",
    "        class_list.append(item_class)\n",
    "        class_dict[item_class] = [item]\n",
    "    else:\n",
    "        class_dict[item_class].append(item)\n",
    "\n",
    "#parsing strings of subdicts, see Objective 4 for explanation\n",
    "def reformat(dict_in):\n",
    "    updated_dict = {}\n",
    "    for key in dict_in.keys():\n",
    "        attribute = dict_in[key]\n",
    "        if key == 'blob' and type(attribute) is str:\n",
    "            if '{' in attribute:\n",
    "                attribute = attribute.replace(\"L,\", \",\")\n",
    "                attribute = attribute.replace(\"L}\", \"}\")\n",
    "                attribute = attribute.replace(\"u\\'\", \"\\'\")\n",
    "                try:\n",
    "                    attribute = ast.literal_eval(attribute)\n",
    "                except:\n",
    "                    print(dict_in)\n",
    "        if type(attribute) is dict:\n",
    "            updated_dict[key] = reformat(attribute)\n",
    "        elif type(attribute) is list:\n",
    "        #WARNING: This does not account for n-dimensional lists\n",
    "            updated_list = []\n",
    "            for entry in attribute:\n",
    "                if type(entry) is dict:\n",
    "                    updated_list.append(reformat(entry))\n",
    "                else:\n",
    "                    updated_list.append(entry)\n",
    "            updated_dict[key] = updated_list\n",
    "        else:\n",
    "            updated_dict[key] = attribute\n",
    "    return updated_dict\n",
    "\n",
    "for key_value in class_dict.keys():\n",
    "    updated_values = []\n",
    "    for entry in class_dict[key_value]:\n",
    "        updated_entry = reformat(entry)\n",
    "        updated_values.append(updated_entry)\n",
    "    class_dict[key_value] = updated_values\n",
    "\n",
    "file_path_dict = {}\n",
    "\n",
    "for class_type in class_dict.keys():\n",
    "    holder_dict = {'content': class_dict[class_type]}\n",
    "    path = 'data_exploration_TEST/' + class_type + '.json'\n",
    "    file_path_dict[class_type] = path\n",
    "    with open('data_exploration_TEST/' + class_type + '.json', 'w') as write_json:\n",
    "        json.dump(holder_dict, write_json)\n",
    "\n",
    "with open('data_exploration_TEST/relative_class_file_paths.json', 'w') as write_json:\n",
    "        json.dump(file_path_dict, write_json)"
   ]
  },
  {
   "source": [
    "# Objective 3\n",
    "Variances in the structure of objects even within the same class need to be noted and accounted for. Each dictionary contains a list of the possible structures within a class. Attributes are treated as keys in the dictionary, where the values are their corresponding dtypes or sub-Attributes with their own dictionaries.\n",
    "The end result is a JSON object where the primary Attributes are each class type, containing a list of dictionaries of each possible structure within that class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class_attributes_dict = {}\n",
    "\n",
    "def dictparse(item):\n",
    "    #A bit messy, but seems to be accurate. Had to workaround some strange formatting, long dtypes, and unicode\n",
    "    attribute_dict = {}\n",
    "    for key in item.keys():\n",
    "        attribute = item[key]\n",
    "        # if key == 'blob' and type(attribute) is str:\n",
    "        #     if '{' in attribute:\n",
    "        #         attribute = attribute.replace(\"L,\", \",\")\n",
    "        #         attribute = attribute.replace(\"L}\", \"}\")\n",
    "        #         attribute = attribute.replace(\"u\\'\", \"\\'\")\n",
    "        #         try:\n",
    "        #             attribute = ast.literal_eval(attribute)\n",
    "        #         except:\n",
    "        #             print(item)\n",
    "        if type(attribute) is dict:\n",
    "            attribute_dict[key] = dictparse(attribute)\n",
    "        elif type(attribute) is list:\n",
    "            #WARNING: This does not account for n-dimensional lists\n",
    "            for entry in attribute:\n",
    "                if type(entry) is dict:\n",
    "                    attribute_dict[key] = dictparse(entry)\n",
    "                else:\n",
    "                    attribute_dict[key] = str(type(attribute))\n",
    "        else:\n",
    "            attribute_dict[key] = str(type(attribute))\n",
    "    return attribute_dict\n",
    "\n",
    "for class_type in class_dict.keys():\n",
    "    class_attributes_dict[class_type] = []\n",
    "    for item in class_dict[class_type]:\n",
    "        item_dict = dictparse(item)\n",
    "        if item_dict not in class_attributes_dict[class_type]:\n",
    "            class_attributes_dict[class_type].append(item_dict)\n",
    "\n",
    "with open('data_exploration_TEST/class_attributes.json', 'w') as write_json:\n",
    "        json.dump(class_attributes_dict, write_json)"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "source": [
    "# Objective 4\n",
    "In order to correctly flatten the json data, subdictionaries in entries that are enclosed by double quotes need to be properly formatted into dictionaries/JSON. This fucntionality will be added to Objective 2 and removed from Objective 3. It is also worth keeping in mind that each entry in the list under the content header will need to be flattened seperately and incrementally added to the dataframe, otherwise every entry will be along the x-axis. Additionally, the different data formats for different classes as displayed in Objective 3 may introduce none/NaN values. These will need to be imputed a some point and may cause issues exporting the dataframes to csv or ingesting them into data visalization software/libraries. Thankfully, imputation will be made easier by the steps taken to document each "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   content_0_classType  content_0_operationFlags content_0_procname  \\\n",
       "0                    0                      2048             zygote   \n",
       "\n",
       "  content_0_low_0_sysname content_0_low_0_ts  content_0_low_0_id  \\\n",
       "0                    pipe     1545638795.518                 327   \n",
       "\n",
       "  content_0_low_0_blob_type content_0_low_0_blob_filename  \\\n",
       "0           read/write pipe         anonymous pipe [read]   \n",
       "\n",
       "  content_0_low_0_type  content_0_low_0_read fd  ... content_2_low_0_read fd  \\\n",
       "0              SYSCALL                       36  ...                     106   \n",
       "\n",
       "  content_2_low_1_sysname  content_2_low_1_ts content_2_low_1_write fd  \\\n",
       "0                    pipe      1545638805.521                      113   \n",
       "\n",
       "  content_2_low_1_blob_type content_2_low_1_blob_filename  \\\n",
       "0           read/write pipe        anonymous pipe [write]   \n",
       "\n",
       "   content_2_low_1_type  content_2_low_1_id content_2_tid  content_2_class  \n",
       "0               SYSCALL               21746          1163   FS PIPE ACCESS  \n",
       "\n",
       "[1 rows x 57 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content_0_classType</th>\n      <th>content_0_operationFlags</th>\n      <th>content_0_procname</th>\n      <th>content_0_low_0_sysname</th>\n      <th>content_0_low_0_ts</th>\n      <th>content_0_low_0_id</th>\n      <th>content_0_low_0_blob_type</th>\n      <th>content_0_low_0_blob_filename</th>\n      <th>content_0_low_0_type</th>\n      <th>content_0_low_0_read fd</th>\n      <th>...</th>\n      <th>content_2_low_0_read fd</th>\n      <th>content_2_low_1_sysname</th>\n      <th>content_2_low_1_ts</th>\n      <th>content_2_low_1_write fd</th>\n      <th>content_2_low_1_blob_type</th>\n      <th>content_2_low_1_blob_filename</th>\n      <th>content_2_low_1_type</th>\n      <th>content_2_low_1_id</th>\n      <th>content_2_tid</th>\n      <th>content_2_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2048</td>\n      <td>zygote</td>\n      <td>pipe</td>\n      <td>1545638795.518</td>\n      <td>327</td>\n      <td>read/write pipe</td>\n      <td>anonymous pipe [read]</td>\n      <td>SYSCALL</td>\n      <td>36</td>\n      <td>...</td>\n      <td>106</td>\n      <td>pipe</td>\n      <td>1545638805.521</td>\n      <td>113</td>\n      <td>read/write pipe</td>\n      <td>anonymous pipe [write]</td>\n      <td>SYSCALL</td>\n      <td>21746</td>\n      <td>1163</td>\n      <td>FS PIPE ACCESS</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 57 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#sample flattening of a test json into csv\n",
    "path = file_path_dict['FS PIPE ACCESS']\n",
    "\n",
    "with open(path) as read:\n",
    "    json_to_flat = json.load(read)\n",
    "\n",
    "flat = flatten(json_to_flat)\n",
    "flat = json_normalize(flat)\n",
    "\n",
    "flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}